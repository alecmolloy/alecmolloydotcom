<!doctype html>
<html lang="en">

<head>
	<title>Face tracker</title>
	<meta charset="utf-8">
	<style>
		#content {
			position: relative;
		}

		#overlay {
			position: absolute;
			top: 0px;
			left: 0px;
			-o-transform: scaleX(-1);
			-webkit-transform: scaleX(-1);
			transform: scaleX(-1);
			-ms-filter: fliph;
			/*IE*/
			filter: fliph;
			/*IE*/
			width: 600px;
			height: 450px;
		}

		#videoel {
			-o-transform: scaleX(-1);
			-webkit-transform: scaleX(-1);
			transform: scaleX(-1);
			-ms-filter: fliph;
			/*IE*/
			filter: fliph;
			/*IE*/
			width: 600px;
			height: 450px;
		}

		#content {
			margin-top: 50px;
			margin-left: auto;
			margin-right: auto;
			max-width: 600px;
		}

		#sketch,
		#filter {
			display: none;
		}

		#controls {
			text-align: center;
		}
	</style>

</head>

<body>
	<script src="js/clmtrackr.js"></script>
	<script src="js/model_pca_20_svm_emotionDetection.js"></script>
	<script src="js/emotion_classifier.js"></script>
	<script src="js/emotionmodel.js"></script>
	<div id="content">
		<div id="container">
			<video id="videoel" width="400" height="300" preload="auto" loop>
			</video>
			<canvas id="overlay" width="400" height="300"></canvas>
		</div>
		<canvas id="sketch" width="400" height="300"></canvas>
		<div id="controls">
			<input class="btn" type="button" value="wait, loading video" disabled="disabled" onclick="startVideo()" id="startbutton"></input>
			<input type="file" class="btn" id="files" name="files[]">
		</div>
		<script>
			var vid = document.getElementById('videoel');
			var overlay = document.getElementById('overlay');
			var overlayCC = overlay.getContext('2d');

			/********** check and set up video/webcam **********/

			function enablestart() {
				var startbutton = document.getElementById('startbutton');
				startbutton.value = "start";
				startbutton.disabled = null;
			}

			navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
			window.URL = window.URL || window.webkitURL || window.msURL || window.mozURL;

			// check for camerasupport
			if (navigator.getUserMedia) {
				// set up stream

				var videoSelector = {
					video: true
				};
				if (window.navigator.appVersion.match(/Chrome\/(.*?) /)) {
					var chromeVersion = parseInt(window.navigator.appVersion.match(/Chrome\/(\d+)\./)[1], 10);
					if (chromeVersion < 20) {
						videoSelector = "video";
					}
				};

				navigator.getUserMedia(videoSelector, function (stream) {
					if (vid.mozCaptureStream) {
						vid.mozSrcObject = stream;
					} else {
						vid.src = (window.URL && window.URL.createObjectURL(stream)) || stream;
					}
					vid.play();
				}, function () {
					//insertAltVideo(vid);
					alert("There was some problem trying to fetch video from your webcam. If you have a webcam, please make sure to accept when the browser asks for access to your webcam.");
				});
			} else {
				//insertAltVideo(vid);
				alert("This demo depends on getUserMedia, which your browser does not seem to support. :(");
			}

			vid.addEventListener('canplay', enablestart, false);

			/*********** setup of emotion detection *************/

			var ctrack = new clm.tracker({
				useWebGL: true
			});
			ctrack.init(pModel);

			function startVideo() {
				// start video
				vid.play();
				// start tracking
				ctrack.start(vid);
				// start loop to draw face
				drawLoop();
			}

			function drawLoop() {
				requestAnimationFrame(drawLoop);
				overlayCC.clearRect(0, 0, 400, 300);
				if (ctrack.getCurrentPosition()) {
					ctrack.draw(overlay);
				}
				var cp = ctrack.getCurrentParameters();

				var er = ec.meanPredict(cp);
				console.log()
			}

			var ec = new emotionClassifier();
			ec.init(emotionModel);
			var emotionData = ec.getBlank();
		</script>
	</div>
</body>

</html>
